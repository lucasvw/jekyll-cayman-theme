---
layout: post
title:  "Simulation of people randomly giving money away"
date:   2017-06-22 12:00:00
categories: main
comments: true
---

This morning I saw a tweet mentioning an [article][1] with the exciting title:

**Counterintuitive problem: Everyone in a room keeps giving dollars to random others. Youâ€™ll never guess what happens next**

So naturally, I was quite excited and wanted to see what happens next! The problem under consideration is:

*Imagine a room full of 100 people with 100 dollars each. With every tick of the clock, every person with money gives a dollar to one randomly chosen other person. After some time progresses, how will the money be distributed?*

Dan Goldstein, writer of the [article][1] argues that many people believe that the money gets more or less evenly distributed. Sometimes you get some, sometimes you lose some, that's the idea.

Turns out, this is not really the case (or actually *really not*). To show this, Dan Goldstein made a simulation in R and a movie to show the results. What you see is the amount of money each person has for each round. The bottom figure is the interesting one, individuals (on the x-axis) are sorted by the amount of money they possess, so you can actually see the distribution of the money as time passes.

{%raw%}
<video width="640" height="400" controls preload> 
    <source src="http://www.decisionsciencenews.com/wp-content/uploads/2017/06/dollar_stacked2.mp4?_=1"></source> 
</video>
{% endraw %}

The simulation made by Dan, is an exact simulation. For each round, each *player* with money picks at random the *player* to give their dollar to. Then all the money is counted and the next round can begin. I was wondering if I could come up with a simulation based on probability and statistics.

Here is my train of thought:

- There are $$m$$ players.
- In each round, each player (with money) gives 1 dollar to some other player.
- In each round, each player will receive either 0, 1, 2, ... or $$m - 1$$ dollar each round.
- Since there are $$m - 1$$ other players, the probability that the dollar from one player is given to a certain other player (in a single round) equals $$p = 1/(m-1)$$.
- Seen from the perspective of one player: there are $$m-1$$ other players, that each give with probability $$p = 1/(m-1)$$ a dollar to me (in a single round).
- That sounds a lot like a binomial distribution, the distribution of the number of successes (does other player $$i$$ give their dollar to me?) in a sequence of $$n$$ ($$=m-1$$) independant experiments all with the same probability ($$p = 1 / (m-1)$$).
- The binomial distribution with $$n$$ experiments, $$k$$ successes and probability $$p$$ of a success is given by: 
{% raw %}
\begin{align}
	\Pr(X = k) = {n \choose k}p^k(1-p)^{n-k}
\end{align}
{% endraw %}

Now we can draw $$m$$ samples from this distribution to denote the amount of money each player obtains in a single round.

However, there is no guarentee that the sum of these samples actually amounts to the number of money that is being circulated each round ($$m$$ players $$ \times 1$$ dollar = $$m$$ dollar). 
Nonetheless, we know the mean of the binomial distribution equals $$np = (m-1)*\frac{1}{m-1} = 1$$. So each player is expected to gain a single dollar each round. Because this is also the amount each person gives away, the *expected* amount of money in the game will remain constant. For now, I am quite okay with this assumption.

With the binomial distribution we can generate the following (incomplete) pay-off table.

| Money lost    | Money gained  | Net money  | Probability |
| :-----------: |:-------------:| :-----:    | :-----: |
| 1            | 0             | -1         | 36.6%|
| 1            | 1             |   0        | 37.0%|
| 1            | 2             |    1       | 18.5%|
| 1            | 3             |    2       | 6.1%|
| 1            | 4             |    3       | 1.5%|
| 1            | 5            |    2       | 0.3%|
| ..  | .. | .. | .. |
| 1            | 99            | 98 | $$\approx$$ 0.0%|

The following video shows a single *run* of 50 people distributing money for around 5000 *rounds*, they start with 50 dollar each.

{%raw%}
<video width="640" height="400" controls preload> 
    <source src="/assets/videos/money.mp4"></source> 
</video>
{% endraw %}

**Edit based on a question from Dan Goldstein**

This model works fine for as long as all players have at least 1 dollar. If this is not the case, then those people who don't have money, cannot participate in giving money (naturally, they can still receive money). So far, the model does not take this into account. Initially, I thought the model could be easily extended to cover this case. When we denote the amount of people who don't have money in round $$i$$ by $$l_{(i)}$$ then we set the parameters for the binomial distribution in round $$i$$ to:
{% raw %}
\begin{align}
    n_{(i)} &= m - 1 - l_{(i)} \\\\\\\\
    p_{(i)} &= \frac{1}{1 - m}
\end{align}
{% endraw %}
The probability that a player receives payment from another one thus remains the same, but the amount of people that distribute money is reduced by the people without money. Seems easy, seems logical. However, if we compute the total amount to be spend ($$m-l$$) in each round no longer equals the expected amount to be received $$(m\cdot n \cdot p)$$. As can be seen from:
{% raw %}
\begin{align}
    m \cdot n \cdot p &\stackrel{?}{=} m - l \\\\\\\\
    m \cdot (m - 1 -l) \cdot \frac{1}{m-1} &\stackrel{?}{=} m - l \\\\\\\\
    m^2 - m - ml &\stackrel{?}{=} (m - l)(m - 1) \\\\\\\\
    0 &\stackrel{?}{=} l \\\\\\\\
\end{align}
{% endraw %}
Which does not hold whenever $$l \neq 0 $$. Thinking a little more about the problem one can see that we actually have two different regimes, depending on people have money or not. For those people with money, the rules above for $$n$$ and $$p$$ are correct. But for people without money, the amount of people who can give them money $$(n)$$ becomes: $$n = (m - 1) - (l-1) = m - l$$. Which translates to *all the other people* $$(m-1)$$ minus *the people who don't have any money, except me* $$(l - 1)$$. Let's do the math to see if this checks out:
{% raw %}
\begin{align}
    m \cdot n \cdot p &\stackrel{?}{=}  m - l \\\\\\\\    
    (m-l) \cdot \frac{m-1-l}{m-1} + l \cdot \frac{m-l}{m-1} &\stackrel{?}{=} m - l \\\\\\\\
    \frac{m^2 - lm - m + l}{m-1} &\stackrel{?}{=} m - l \\\\\\\\
    \frac{(m-1)(m-l)}{m-1} &\stackrel{?}{=} m - l \\\\\\\\
    m - l &= m - l
\end{align}
{% endraw %}
And it does! This makes the updating of the bank in each round a little more complicated.


{% highlight python %}
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import animation

amount_of_people = 100

n = amount_of_people - 1
p = 1 / n
start_money = 100

bank = start_money*np.ones([amount_of_people])

range = np.arange(amount_of_people)

fig = plt.figure()
ax = fig.add_subplot(1,1,1)

bar = plt.bar(range,bank)

def init():
    return bar

def animate(i):
    global bank, ax
    people_without_money = sum(bank==0)
    smpl_w_money = np.random.binomial(amount_of_people - 1 - people_without_money, p, amount_of_people)
    smpl_wo_money = np.random.binomial(amount_of_people - people_without_money, p, amount_of_people)
    smpl_w_money[bank == 0] = 0
    smpl_wo_money[bank > 0] = 0
    sample = smpl_w_money + smpl_wo_money
    bank = bank + sample - 1*(bank > 0)
    bank = np.sort(bank)
    for rect, y in zip(bar, bank):
        rect.set_height(y)
    ax.set_ylim(0,max(bank))
    ax.set_title(i)
    #print(sum(bank)/amount_of_people)

anim = animation.FuncAnimation(fig, animate, init_func=init,
                               frames=1500, interval=1, blit=False)
plt.show()
{% endhighlight %}






[1]:http://www.decisionsciencenews.com/2017/06/19/counterintuitive-problem-everyone-room-keeps-giving-dollars-random-others-youll-never-guess-happens-next/